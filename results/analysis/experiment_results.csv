experiment_name,experiment_dir,strategy,lora_rank,final_train_loss,final_eval_loss,final_perplexity,trainable_parameters,total_parameters,parameter_efficiency,training_time_seconds,dataset_size,num_epochs,learning_rate,seed,avg_rank,min_rank,max_rank,rank_std,perplexity_per_param,loss_improvement,param_ratio
adaptive_empirical_official,adaptive_empirical_official,empirical,16,0,,,3538944,358362112,0.009875329677708787,88.786559,200,3,0.0003,42,15.208333333333334,9.0,19.0,4.17312000253474,,,1.125
adaptive_linear_decay_official,adaptive_linear_decay_official,linear_decay,16,0,5.106527805328369,165.0961151123047,6291456,361114624,0.01742232405409314,83.510119,200,3,0.0003,42,9.541666666666666,4.0,16.0,3.523482730985857,26.241320786842454,0.03917088067796939,2.0
adaptive_attention_heavy_official,adaptive_attention_heavy_official,attention_heavy,16,0,,,5111808,359934976,0.014202031869222956,90.210599,200,3,0.0003,42,,,,,,,1.625
baseline_rank8_official,baseline_rank8_official,baseline,8,0,5.314709663391113,203.30548095703125,3145728,357968896,0.008787713220759828,87.462698,200,3,0.0003,42,,,,,64.62907185778022,0.0,1.0
baseline_rank16_official,baseline_rank16_official,baseline,16,0,4.897876739501953,134.00494384765625,6291456,361114624,0.01742232405409314,81.788631,200,3,0.0003,42,,,,,21.299512203161914,0.07843004609647763,2.0
